<br/>

# [Multimodal Pre-training Based on Graph Attention Network for Document Understanding](https://arxiv.org/abs/2203.13530)

## TODO List

- [x] 论文主体结构疏离
- [x] 论文主要观点介绍
- [ ] 论文复现

## 1. 论文主题结构

### 1.1 文章摘要

文档智能作为一个相对较新的研究主题，支持许多业务应用程序。它的主要任务是自动阅读、理解和分析文档。但是，由于文档中的格式 (发票，报告，表单等) 和布局的多样性，很难使机器理解文档。在本文中，我们介绍了GraphDoc，这是一种基于多模态图注意的模型，用于各种文档理解任务。通过同时利用文本，布局和图像信息，GraphDoc在多模态框架中进行了预训练。在文档中，文本块很大程度上依赖于其周围的上下文，因此我们将图结构注入到注意力机制中以形成图注意力层，以便每个输入节点只能关注其邻域。每个图形注意层的输入节点由来自文档图像中语义上有意义的区域的文本，视觉和位置特征组成。我们通过门融合层对每个节点进行多模态特征融合。每个节点之间的上下文化由图形注意层建模。GraphDoc通过蒙面句子建模任务仅从320k个未标记文档中学习通用表示。在公开可用的数据集上进行的大量实验结果表明，GraphDoc达到了最先进的性能，这证明了我们提出的方法的有效性。

***

### 1.2 相关工作  

#### 1.2.1 注意力机制

给定一个查询元素和一组关键元素，注意力函数可以根据注意力权重自适应地聚合关键内容，从而衡量查询-密钥对的兼容性。注意力机制作为模型的组成部分，使神经网络能够更多地关注输入的相关元素，而不是无关部分。它们首先在自然语言处理 (NLP) 中进行了研究，其中开发了编码器-解码器注意模块以促进神经机器翻译 [18]，[24]。特别地，自我注意 (也称为内部注意) 是一种注意机制，该机制与单个序列的不同位置相关，以便计算序列的表示。自我注意已成功用于各种任务，包括阅读理解，抽象摘要和文本包含。具有里程碑意义的作品Transformer [18] 提出了完全依靠自我注意来计算其输入和输出表示的转导模型，并且大大超过了过去作品的性能。  
虽然自我注意功能强大，但变压器的计算和内存开销是序列长度的二次方。为了降低自我注意的复杂性，最近提出了一些稀疏变压器。StarTransformer [25] 用星形拓扑代替了全连接的结构，其中每两个不相邻的节点都通过共享的中继节点连接。Longformer [26] 在编码器网络上使用了许多有效的注意模式，并降低了模型复杂度。图形注意网络 [27] 通过参与其邻居来计算图形中每个节点的隐藏表示。

#### 1.2.2 自监督学习

自监督学习是在大规模未标记数据中学习数据的一般表示，并且利用所学习的表示来提高下游任务的性能，对于该下游任务，标记数据的数量是有限的。这对于自然语言处理 [7]，[8]，语音识别 [28]，[29]，计算机视觉 [30]，[31] 尤其成功，并且也是文档理解的活跃研究领域 [9]，[10]。Wav2vec [28]，[29] 通过噪声对比二进制分类任务对大量未标记的音频数据进行预训练，然后将所得的表示形式用于改进声学模型训练。MoCo [30]，[31] 为无监督学习构建大型且一致的即时词典，并带来相反的损失。MoCo学到的表述很好地转移到下游任务中。

#### 1.2.3 文档预训练

利用文档中每个语义上有意义的组件的文本，视觉和位置信息。Layoutllmv2 [10] 通过将图像信息与文本和布局集成在一起，对LayoutLM进行了改进，并利用Transformer体系结构在预训练阶段学习视觉和文本信息之间的跨模态交互。由于空间和视觉依赖性可能在变压器层之间有所不同，DocFormer [16] 将视觉，文本和空间特征结合在一起。与以前的方法不同，Self-Doc [11] 采用语义上有意义的组件 (例如，文本块，标题，图形) 作为模型输入，而不是孤立的单词。它将预先提取的RoI特征和句子嵌入作为输入，并使用跨模态编码器对文本和视觉信息的执行学习进行建模。UniDoc [12] 通过使用三个自我监督的任务，鼓励表示来建模句子，学习相似性和对齐方式，从而改善了自我文档。

***

### 1.3 主要方法

#### 1.3.1 文本编码

由于文档中的文本内容以 2D 结构呈现，因此需要使用布局信息对文本进行编码。在 LayoutLMv2 [10] 之后，我们将所有坐标标准化和离散化为 [0, 512] 范围内的整数，并使用两个嵌入层分别嵌入 x 轴特征和 y 轴特征。给定第 i 个语义区域 bi 的归一化边界框，我们计算表示为 wi 和 hi 的框的宽度和高度,其顶点坐标
表示为(xiv, yiv),从左上角开始，文本布局特征为左上角坐标、右下角坐标、宽、高等6个特征(xi0, yi0, xi2, yi2, w, h)构造的embedding为布局特征
则布局特征表示为  
![](https://latex.codecogs.com/gif.image?\bg{white}I_{i}&space;=&space;[Emb_{x}(x_{i0},x_{i2},w_{i});Emb_{y}(y_{i0},y_{i2},h_{i})],&space;0\leq&space;i\leq&space;n{\color{white}})  
其中[;]表示两个特征进行concat  
而文本编码Si表示为:  
<img src="https://latex.codecogs.com/gif.image?\dpi{110}\bg{white}S_{i}=Proj(SentenceEmb(t_{i}))&plus;I_{i}" title="https://latex.codecogs.com/gif.image?\dpi{110}\bg{white}S_{i}=Proj(SentenceEmb(t_{i}))+I_{i}" />  
其中 SentenceEmb使用Sentence-Bert对文本进行编码 S0表示[CLS]

#### 1.3.2 图像编码

使用带有FPN [444] 的Swin变压器 [22] 作为视觉编码器的主干。首先在PubLayNet [34] 数据集上对主干进行预训练，以使提取的视觉特征更具语义性。将文档图像I的大小调整为512 × 512，然后馈送到视觉主干中，以生成具有四个特征图 {P2，P3，P4，P5} 的特征金字塔，如图4所示。输出P2是来自FPN的特征图，其具有输入图像的1/4大小。之后，根据bi，RoIAlign [21] 从P2中提取每个语义区域的图像特征。视觉嵌入vi的计算方法如下:  
<img src="https://latex.codecogs.com/gif.image?\dpi{110}\bg{white}V_{i}&space;=&space;Proj(Pool(Backbone(I)))&plus;I_{i}" title="https://latex.codecogs.com/gif.image?\dpi{110}\bg{white}V_{i} = Proj(Pool(Backbone(I)))+I_{i}" />

#### 1.3.3 门融合层

以前的大多数预训练模型 [10]，[35] 通过从文本，视觉和布局中收集多模态信息来产生嵌入序列，然后执行变压器网络以建立对不同模态的深度融合。在我们的工作中，我们采用语义上有意义的组件 (例如，文本块，表，图) 作为模型输入。由于每个组件都有其相应的多模态信息，因此我们设计了栅极融合层以显式融合来自每个模态的信息。此外，我们认为文本和图像之间的依赖性可能在图形注意层之间有所不同，这在我们的消融实验中得到了验证。受ResNet [23] 的启发，我们使跨图形注意层可访问的视觉信息充当信息残留连接。栅极融合层的设计如下:  
<img src="https://latex.codecogs.com/gif.image?\dpi{110}\bg{white}Z_{i}^{l}=\sigma(W_{2\delta}(W_{1}[V_{i};h_{i}^{i-1}]+b_{1})+b_{2}) \" />  
<img src="https://latex.codecogs.com/gif.image?\dpi{110}\bg{white}m_{i}^{i}=h_{i}^{l-1}+z_{i}^{l}v_{i}" />

#### 1.3.4 图注意力层

观察到文档中的文本块更多地依赖于其周围的上下文是一种强大的归纳偏差但是，以前的预训练模型 [9]，[10]，[11]，[12] 应用变压器在预训练阶段从头开始学习这种偏差。受GAN [27] 和StartTransformer [25] 的启发，我们设计了图形注意层，通过遵循自我注意策略来关注其邻居，从而计算图形中每个节点的隐藏表示。如图5所示，每个节点只关注其邻域节点和一个全局节点，这可以帮助模型从本地和全局两个方面理解文档。
第l个图注意层的输入是n个节点的特征，Ml = ml节点特征Hl = Hl n。该层产生一组新的 结点特征， 作为其输出。遵循original原始的自我注意机制 [18]，我们计算第j个节点和第i个节点之间的注意分数如下。  
<img src="https://latex.codecogs.com/gif.image?\dpi{110}\bg{white}e_{i,j}=(W^{q}m_{i}^{l})(W^{k}m_{j}^{l})" />

***

## 2. 文章主要观点

本篇文章相较于其他Document Intelligent 算法而言，1. 在图像信息与文本信息(text_embedding+layout_embedding)进行融合时
通过门融合层来控制相互融合的权重，并在消融实验中表明该方式是有效的。
2.在融合node直线信息时，并不是和所有的node进行attention运算，而时通过计算与本node欧氏距离最近的top_k个node进行计算
3.提出使用在图注意力计算时添加node之间的相对的坐标关系。

***

## 作者

- [@watcher](https://github.com/mlshenkai)
