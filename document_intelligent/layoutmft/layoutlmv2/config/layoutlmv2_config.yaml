device: "cuda"
---
pre_model:
  layoutlmv2-base-uncased: "https://huggingface.co/microsoft/layoutlmv2-base-uncased/resolve/main/config.json"
  layoutlmv2-large-uncased: "https://huggingface.co/microsoft/layoutlmv2-large-uncased/resolve/main/config.json"

---
model:
  vocab_size: 30522
  hidden_size: 768
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: "gelu"
  hidden_dropout_prob: 0.1
  attention_prob_dropout_prob: 0.1
  max_position_embeddings: 512
  type_vocab_size: 2
  initializer_range: 0.02
  layer_norm_eps: 1e-12
  pad_token_id: 0
  gradient_checkpointing: False
  max_2d_position_embeddings: 1024
  max_rel_pos: 128
  rel_pos_bins: 32
  fast_qkv: True
  max_rel_2d_pos: 256
  rel_2d_pos_bins: 64
  convert_sync_batchnorm: True
  image_feature_pool_shape: [7, 7, 256]
  coordinate_size: 128
  shape_size: 128
  has_relation_attention_bias: True
  has_spatial_attention_bias: True
  has_visual_segment_embedding: False
  chunk_size_feed_forward: -1
